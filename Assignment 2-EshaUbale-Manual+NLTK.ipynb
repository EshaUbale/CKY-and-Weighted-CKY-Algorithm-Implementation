{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6acc0db",
   "metadata": {},
   "source": [
    "# Part 2 - Programming CKY Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1010287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a49084e-678d-4319-86a5-928c433b2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> JJ NP\n",
    "VP -> VP NP\n",
    "VP -> VP PP\n",
    "PP -> P NP\n",
    "NP -> 'British'\n",
    "JJ -> 'British'\n",
    "NP -> 'left'\n",
    "VP -> 'left'\n",
    "NP -> 'waffles'\n",
    "VP -> 'waffles'\n",
    "P -> 'on'\n",
    "NP -> 'Falklands'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120b272b-e99d-44d4-9adb-dee4d8ef3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting symbol: S\n",
      "Data type of the symbol: <class 'nltk.grammar.Nonterminal'>\n"
     ]
    }
   ],
   "source": [
    "print('Starting symbol:', part2_grammar.start())\n",
    "print('Data type of the symbol:', type(part2_grammar.start()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3739a583-b2a5-4933-9fcd-867ddce4ca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-terminals = {VP, JJ, S, PP, P, NP}\n",
      "Rules: \n",
      "S -> NP VP\n",
      "NP -> JJ NP\n",
      "VP -> VP NP\n",
      "VP -> VP PP\n",
      "PP -> P NP\n",
      "NP -> 'British'\n",
      "JJ -> 'British'\n",
      "NP -> 'left'\n",
      "VP -> 'left'\n",
      "NP -> 'waffles'\n",
      "VP -> 'waffles'\n",
      "P -> 'on'\n",
      "NP -> 'Falklands'\n"
     ]
    }
   ],
   "source": [
    "non_terminals = set()\n",
    "productions = part2_grammar.productions()\n",
    "for rule in productions:\n",
    "    non_terminals.add(rule.lhs())\n",
    "print(\"Non-terminals =\", non_terminals)\n",
    "nonterms = list(non_terminals)\n",
    "print(\"Rules: \")\n",
    "for rule in productions:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f1a0b2-f0b4-429f-8f9a-8005efcd64aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of trees = 2\n",
      "(S\n",
      "  (NP British)\n",
      "  (VP (VP (VP left) (NP waffles)) (PP (P on) (NP Falklands))))\n",
      "(S\n",
      "  (NP (JJ British) (NP left))\n",
      "  (VP (VP waffles) (PP (P on) (NP Falklands))))\n"
     ]
    }
   ],
   "source": [
    "sentence = \"British left waffles on Falklands\"\n",
    "words = sentence.split()\n",
    "parser = nltk.ChartParser(part2_grammar)\n",
    "trees = list(parser.parse(words))\n",
    "print(\"num of trees =\", len(trees))\n",
    "print(trees[0])\n",
    "print(trees[1])\n",
    "#trees[0]\n",
    "#trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96ba358-130f-496d-b85d-bb3d56a27b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cky2(words, grammar):\n",
    "    n = len(words)\n",
    "    # Create table with n + 1 rows and columns, with each cell containing empty set\n",
    "    table = [[set() for i in range(n + 1)] for i in range(n + 1)]\n",
    "    \n",
    "    # initialize the diagonal elements of the table\n",
    "    for i in range(n):\n",
    "        for production in grammar.productions(rhs=words[i]):\n",
    "                table[i][i + 1].add(production.lhs())\n",
    "    \n",
    "    for width in range(2, n + 1):\n",
    "        for i in range(0, n - width + 1):\n",
    "            for j in range(1, width):\n",
    "                non_term1 = table[i][i + j]\n",
    "                non_term2 = table[i + j][i + width]\n",
    "                for nt1 in non_term1:\n",
    "                    productions = grammar.productions(rhs=nt1)\n",
    "                    for production in productions:\n",
    "                        if production.rhs()[1] in non_term2:\n",
    "                            table[i][i + width].add(production.lhs())\n",
    "\n",
    "    t2 =[]\n",
    "    for i in range(n):\n",
    "        r = []\n",
    "        for j in range(1, n + 1):\n",
    "            cell = table[i][j]\n",
    "            if cell:\n",
    "                r.append(', '.join([x.symbol() for x in cell]))\n",
    "            else:\n",
    "                r.append('-')\n",
    "        t2.append(r)\n",
    "        \n",
    "    print(tabulate(t2, headers=words, tablefmt='grid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30119ef6-5304-4b60-9348-c9cebd66d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+------+-------------+\n",
      "| British   | left   | waffles   | on   | Falklands   |\n",
      "+===========+========+===========+======+=============+\n",
      "| JJ, NP    | NP, S  | S         | -    | S           |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | VP, NP | VP, S     | -    | VP, S       |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | -      | VP, NP    | -    | VP          |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | -      | -         | P    | PP          |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | -      | -         | -    | NP          |\n",
      "+-----------+--------+-----------+------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# Using NLTK\n",
    "cky2(words, part2_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7ebb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_terminals = [\"NP\", \"VP\", \"JJ\", \"PP\", \"P\"]\n",
    "terminals = [\"British\", \"left\", \"waffles\", \"on\", \"Falklands\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854aa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules of the grammar\n",
    "R = {\n",
    "    \"S\": [[\"NP\", \"VP\"]],\n",
    "    \"NP\": [[\"JJ\", \"NP\"], [\"British\"], [\"left\"], [\"waffles\"], [\"Falklands\"]],\n",
    "    \"VP\": [[\"VP\", \"NP\"], [\"VP\", \"PP\"], [\"left\"], [\"waffles\"]],\n",
    "    \"PP\": [[\"P\", \"NP\"]],\n",
    "    \"JJ\": [[\"British\"]],\n",
    "    \"P\": [[\"on\"]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21911b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the CYK Algorithm\n",
    "def cykParse(w):\n",
    "    n = len(w)\n",
    "\n",
    "    # Initialize the table\n",
    "    T = [[set() for j in range(n)] for i in range(n)]\n",
    "\n",
    "    # Filling in the table\n",
    "    for j in range(n):\n",
    "        for lhs, rule in R.items():\n",
    "            for rhs in rule:\n",
    "                if len(rhs) == 1 and rhs[0] == w[j]:\n",
    "                    T[j][j].add(lhs)\n",
    "\n",
    "        for i in range(j, -1, -1):\n",
    "            for k in range(i, j):\n",
    "                for lhs, rule in R.items():\n",
    "                    for rhs in rule:\n",
    "                        if len(rhs) == 2 and rhs[0] in T[i][k] and rhs[1] in T[k+1][j]:\n",
    "                            T[i][j].add(lhs)\n",
    "\n",
    "    # Printing the final parse table\n",
    "    table = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            row.append(', '.join(T[i][j]) if T[i][j] else '-')\n",
    "        table.append(row)\n",
    "    print(tabulate(table, headers=w, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce558c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+------+-------------+\n",
      "| British   | left   | waffles   | on   | Falklands   |\n",
      "+===========+========+===========+======+=============+\n",
      "| JJ, NP    | NP, S  | S         | -    | S           |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | VP, NP | VP, S     | -    | VP, S       |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | -      | VP, NP    | -    | VP          |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | -      | -         | P    | PP          |\n",
      "+-----------+--------+-----------+------+-------------+\n",
      "| -         | -      | -         | -    | NP          |\n",
      "+-----------+--------+-----------+------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# Given string\n",
    "sentence = \"British left waffles on Falklands\"\n",
    "T = cykParse(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c773bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "566d0074",
   "metadata": {},
   "source": [
    "# Part 3 -  Weighted CKY Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00db9cf-0462-41b9-ac02-a73327b09aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "part3_grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "S -> NP VP [1.0]\n",
    "PP -> P NP [1.0]\n",
    "VP -> V NP [0.7]\n",
    "VP -> VP PP [0.3]\n",
    "P -> 'with' [1.0]\n",
    "V -> 'saw' [1.0]\n",
    "NP -> NP PP [0.4]\n",
    "NP -> 'astronomers' [0.1]\n",
    "NP -> 'ears' [0.18]\n",
    "NP -> 'saw' [0.04]\n",
    "NP -> 'stars' [0.18]\n",
    "NP -> 'telescopes' [0.1]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e909179-7735-4f32-8f0e-a561f1d71531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "print(part3_grammar.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9229aca4-820b-438d-9394-e355dd3584a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of trees = 2\n",
      "(S\n",
      "  (NP astronomers)\n",
      "  (VP (VP (V saw) (NP stars)) (PP (P with) (NP ears))))\n",
      "(S\n",
      "  (NP astronomers)\n",
      "  (VP (V saw) (NP (NP stars) (PP (P with) (NP ears)))))\n"
     ]
    }
   ],
   "source": [
    "sentence = \"astronomers saw stars with ears\"\n",
    "words = sentence.split()\n",
    "parser = nltk.ChartParser(part3_grammar)\n",
    "trees = list(parser.parse(words))\n",
    "print(\"num of trees =\", len(trees))\n",
    "print(trees[0])\n",
    "print(trees[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98d2a28-d8f2-4a1a-9f01-d765417c73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+---------+--------+--------+\n",
      "| astronomers   | saw   | stars   | with   | ears   |\n",
      "+===============+=======+=========+========+========+\n",
      "| NP            | -     | S       | -      | S      |\n",
      "+---------------+-------+---------+--------+--------+\n",
      "| -             | NP, V | VP      | -      | VP     |\n",
      "+---------------+-------+---------+--------+--------+\n",
      "| -             | -     | NP      | -      | NP     |\n",
      "+---------------+-------+---------+--------+--------+\n",
      "| -             | -     | -       | P      | PP     |\n",
      "+---------------+-------+---------+--------+--------+\n",
      "| -             | -     | -       | -      | NP     |\n",
      "+---------------+-------+---------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Using NLTK\n",
    "cky2(words, part3_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b48f599f-9256-4414-9bb8-ec933cc43da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |[-] . . . .| [0:1] 'astronomers'                  [1.0]\n",
      "  |. [-] . . .| [1:2] 'saw'                          [1.0]\n",
      "  |. . [-] . .| [2:3] 'stars'                        [1.0]\n",
      "  |. . . [-] .| [3:4] 'with'                         [1.0]\n",
      "  |. . . . [-]| [4:5] 'ears'                         [1.0]\n",
      "  |. . . . [-]| [4:5] 'ears'                         [1.0]\n",
      "  |. . . [-] .| [3:4] 'with'                         [1.0]\n",
      "  |. . . [-] .| [3:4] P  -> 'with' *                 [1.0]\n",
      "  |. . . [-> .| [3:4] PP -> P * NP                   [1.0]\n",
      "  |. . . > . .| [3:3] PP -> * P NP                   [1.0]\n",
      "  |. . . > . .| [3:3] P  -> * 'with'                 [1.0]\n",
      "  |. . [-] . .| [2:3] 'stars'                        [1.0]\n",
      "  |. [-] . . .| [1:2] 'saw'                          [1.0]\n",
      "  |. [-] . . .| [1:2] V  -> 'saw' *                  [1.0]\n",
      "  |. > . . . .| [1:1] V  -> * 'saw'                  [1.0]\n",
      "  |[-] . . . .| [0:1] 'astronomers'                  [1.0]\n",
      "  |. [-> . . .| [1:2] VP -> V * NP                   [0.7]\n",
      "  |. > . . . .| [1:1] VP -> * V NP                   [0.7]\n",
      "  |. . [-] . .| [2:3] NP -> 'stars' *                [0.18]\n",
      "  |. . > . . .| [2:2] S  -> * NP VP                  [1.0]\n",
      "  |. . > . . .| [2:2] NP -> * NP PP                  [0.4]\n",
      "  |. . [-> . .| [2:3] S  -> NP * VP                  [0.18]\n",
      "  |. . > . . .| [2:2] NP -> * 'stars'                [0.18]\n",
      "  |. . . [---]| [3:5] PP -> P NP *                   [0.18]\n",
      "  |. . . . [-]| [4:5] NP -> 'ears' *                 [0.18]\n",
      "  |. . . . > .| [4:4] S  -> * NP VP                  [1.0]\n",
      "  |. . . . > .| [4:4] NP -> * NP PP                  [0.4]\n",
      "  |. . . . [->| [4:5] S  -> NP * VP                  [0.18]\n",
      "  |. . . . > .| [4:4] NP -> * 'ears'                 [0.18]\n",
      "  |. [---] . .| [1:3] VP -> V NP *                   [0.126]\n",
      "  |. > . . . .| [1:1] VP -> * VP PP                  [0.3]\n",
      "  |[-] . . . .| [0:1] NP -> 'astronomers' *          [0.1]\n",
      "  |> . . . . .| [0:0] S  -> * NP VP                  [1.0]\n",
      "  |> . . . . .| [0:0] NP -> * NP PP                  [0.4]\n",
      "  |[-> . . . .| [0:1] S  -> NP * VP                  [0.1]\n",
      "  |> . . . . .| [0:0] NP -> * 'astronomers'          [0.1]\n",
      "  |. . . . [->| [4:5] NP -> NP * PP                  [0.072]\n",
      "  |. . [-> . .| [2:3] NP -> NP * PP                  [0.072]\n",
      "  |[-> . . . .| [0:1] NP -> NP * PP                  [0.04000000000000001]\n",
      "  |. [-] . . .| [1:2] NP -> 'saw' *                  [0.04]\n",
      "  |. > . . . .| [1:1] S  -> * NP VP                  [1.0]\n",
      "  |. > . . . .| [1:1] NP -> * NP PP                  [0.4]\n",
      "  |. [-> . . .| [1:2] S  -> NP * VP                  [0.04]\n",
      "  |. > . . . .| [1:1] NP -> * 'saw'                  [0.04]\n",
      "  |. [---> . .| [1:3] VP -> VP * PP                  [0.0378]\n",
      "  |. [-> . . .| [1:2] NP -> NP * PP                  [0.016]\n",
      "  |. . [-----]| [2:5] NP -> NP PP *                  [0.01296]\n",
      "  |. . [----->| [2:5] S  -> NP * VP                  [0.01296]\n",
      "  |[-----] . .| [0:3] S  -> NP VP *                  [0.0126]\n",
      "  |. [-------]| [1:5] VP -> V NP *                   [0.009071999999999998]\n",
      "  |. [-------]| [1:5] VP -> VP PP *                  [0.006804]\n",
      "  |. . [----->| [2:5] NP -> NP * PP                  [0.005184]\n",
      "  |. [------->| [1:5] VP -> VP * PP                  [0.0027215999999999994]\n",
      "  |. [------->| [1:5] VP -> VP * PP                  [0.0020412]\n",
      "  |[=========]| [0:5] S  -> NP VP *                  [0.0009071999999999999]\n",
      "  |[=========]| [0:5] S  -> NP VP *                  [0.0006804000000000001]\n",
      "(S\n",
      "  (NP astronomers)\n",
      "  (VP (V saw) (NP (NP stars) (PP (P with) (NP ears))))) (p=0.0009072)\n",
      "(S\n",
      "  (NP astronomers)\n",
      "  (VP (VP (V saw) (NP stars)) (PP (P with) (NP ears)))) (p=0.0006804)\n"
     ]
    }
   ],
   "source": [
    "# parser = nltk.parse.ViterbiParser(part3_grammar)\n",
    "parser = nltk.pchart.InsideChartParser(part3_grammar)\n",
    "parser.trace(3)\n",
    "for parse in parser.parse(words):\n",
    "  print(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5f31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PCFG\n",
    "pcfg = {\n",
    "    (\"S\", (\"NP\", \"VP\")): 1.0,\n",
    "    (\"PP\", (\"P\", \"NP\")): 1.0,\n",
    "    (\"VP\", (\"V\", \"NP\")): 0.7,\n",
    "    (\"VP\", (\"VP\", \"PP\")): 0.3,\n",
    "    (\"P\", \"with\"): 1.0,\n",
    "    (\"V\", \"saw\"): 1.0,\n",
    "    (\"NP\", (\"N\", \"PP\")): 0.4,\n",
    "    (\"NP\", \"astronomers\"): 0.4,\n",
    "    (\"NP\", \"ears\"): 0.18,\n",
    "    (\"NP\", \"stars\"): 0.18,\n",
    "    (\"NP\", \"telescopes\"): 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "756c5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_cyk_parse(sentence, pcfg):\n",
    "    words = sentence.split()\n",
    "    n = len(words)\n",
    "\n",
    "    # Initialize the table for probabilities\n",
    "    table = [[{} for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # Fill in the table\n",
    "    for j in range(n):\n",
    "        for lhs, rhs in pcfg.keys():\n",
    "            if isinstance(rhs, str) and rhs == words[j]:\n",
    "                table[j][j][lhs] = pcfg[(lhs, rhs)]\n",
    "\n",
    "        for i in range(j-1, -1, -1):\n",
    "            for k in range(i, j):\n",
    "                for (X, Y), prob in pcfg.items():\n",
    "                    if isinstance(Y, tuple) and len(Y) == 2:\n",
    "                        for x in table[i][k]:\n",
    "                            for y in table[k+1][j]:\n",
    "                                if (x, y) == Y:\n",
    "                                    if X not in table[i][j]:\n",
    "                                        table[i][j][X] = 0.0\n",
    "                                    table[i][j][X] += table[i][k][x] * table[k+1][j][y] * prob\n",
    "\n",
    "    # Find the most probable parse tree and its probability\n",
    "    max_prob = 0.0\n",
    "    max_parse_tree = None\n",
    "    for key, value in table[0][n-1].items():\n",
    "        if value > max_prob:\n",
    "            max_prob = value\n",
    "            max_parse_tree = key\n",
    "\n",
    "    # Print the parse table\n",
    "    headers = words\n",
    "    table_data = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            row.append(', '.join([f\"{symbol} ({prob:.4f})\" for symbol, prob in table[i][j].items()]) if table[i][j] else '-')\n",
    "        table_data.append(row)\n",
    "\n",
    "    print(\"Parse Table:\")\n",
    "    print(tabulate(table_data, headers=headers))\n",
    "\n",
    "    print(\"\\nMost Probable Parse Tree:\", max_parse_tree)\n",
    "    print(\"Probability:\", max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08f6189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Table:\n",
      "astronomers    saw         stars        with        ears\n",
      "-------------  ----------  -----------  ----------  -----------\n",
      "NP (0.4000)    -           S (0.0504)   -           S (0.0027)\n",
      "-              V (1.0000)  VP (0.1260)  -           VP (0.0068)\n",
      "-              -           NP (0.1800)  -           -\n",
      "-              -           -            P (1.0000)  PP (0.1800)\n",
      "-              -           -            -           NP (0.1800)\n",
      "\n",
      "Most Probable Parse Tree: S\n",
      "Probability: 0.0027216\n"
     ]
    }
   ],
   "source": [
    "sentence = \"astronomers saw stars with ears\"\n",
    "weighted_cyk_parse(sentence, pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1935a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75df981e",
   "metadata": {},
   "source": [
    "# Part 4 - Marginalize Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe89919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalize_parse_trees(sentence, pcfg):\n",
    "    words = sentence.split()\n",
    "    n = len(words)\n",
    "\n",
    "    # Initialize the table for probabilities\n",
    "    table = [[{} for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # Fill in the table\n",
    "    for j in range(n):\n",
    "        for lhs, rhs in pcfg.keys():\n",
    "            if isinstance(rhs, str) and rhs == words[j]:\n",
    "                table[j][j][lhs] = pcfg[(lhs, rhs)]\n",
    "\n",
    "        for i in range(j-1, -1, -1):\n",
    "            for k in range(i, j):\n",
    "                for (X, Y), prob in pcfg.items():\n",
    "                    if isinstance(Y, tuple) and len(Y) == 2:\n",
    "                        for x in table[i][k]:\n",
    "                            for y in table[k+1][j]:\n",
    "                                if (x, y) == Y:\n",
    "                                    if X not in table[i][j]:\n",
    "                                        table[i][j][X] = 0.0\n",
    "                                    table[i][j][X] += table[i][k][x] * table[k+1][j][y] * prob\n",
    "\n",
    "    # Print the parse table\n",
    "    print(\"Parse Table:\")\n",
    "    headers = words\n",
    "    table_data = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            row.append(', '.join([f\"{symbol} ({prob:.4f})\" for symbol, prob in table[i][j].items()]) if table[i][j] else '-')\n",
    "        table_data.append(row)\n",
    "    print(tabulate(table_data, headers=headers))\n",
    "\n",
    "    # Sum up probabilities of all parse trees\n",
    "    total_prob = sum(prob for prob in table[0][n-1].values())\n",
    "\n",
    "    # Print the total probability of the sentence\n",
    "    print(\"\\nTotal Probability of the Sentence:\", total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3936bc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Table:\n",
      "astronomers    saw         stars        with        ears\n",
      "-------------  ----------  -----------  ----------  -----------\n",
      "NP (0.4000)    -           S (0.0504)   -           S (0.0027)\n",
      "-              V (1.0000)  VP (0.1260)  -           VP (0.0068)\n",
      "-              -           NP (0.1800)  -           -\n",
      "-              -           -            P (1.0000)  PP (0.1800)\n",
      "-              -           -            -           NP (0.1800)\n",
      "\n",
      "Total Probability of the Sentence: 0.0027216\n"
     ]
    }
   ],
   "source": [
    "sentence = \"astronomers saw stars with ears\"\n",
    "marginalize_parse_trees(sentence, pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cfd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
